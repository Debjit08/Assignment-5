{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of logistic_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "dPpJUV862FYI",
        "i2e3TlyL57Qs",
        "wCugvl0JdWYL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Debjit08/Assignment-5/blob/Debjit08/Copy_of_Copy_of_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4T-_IsVbweU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "LEAHZv4rIYHX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives:**\n",
        "  * Reframe the median house value predictor (from the preceding exercises) as a binary classification model\n",
        "  * Compare the effectiveness of logisitic regression vs linear regression for a binary classification problem"
      ]
    },
    {
      "metadata": {
        "id": "CnkCZqdIIYHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As in the prior exercises, we're working with the [California housing data set](https://developers.google.com/machine-learning/crash-course/california-housing-data-description), but this time we will turn it into a binary classification problem by predicting whether a city block is a high-cost city block. We'll also revert to the default features, for now."
      ]
    },
    {
      "metadata": {
        "id": "9pltCyy2K3dd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Frame the Problem as Binary Classification\n",
        "\n",
        "The target of our dataset is `median_house_value` which is a numeric (continuous-valued) feature. We can create a boolean label by applying a threshold to this continuous value.\n",
        "\n",
        "Given features describing a city block, we wish to predict if it is a high-cost city block. To prepare the targets for train and eval data, we define a classification threshold of the 75%-ile for median house value (a value of approximately 265000). All house values above the threshold are labeled `1`, and all others are labeled `0`."
      ]
    },
    {
      "metadata": {
        "id": "67IJwZX1Vvjt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Run the cells below to load the data and prepare the input features and targets."
      ]
    },
    {
      "metadata": {
        "id": "fOlbcJ4EIYHd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
        "\n",
        "california_housing_dataframe = california_housing_dataframe.reindex(\n",
        "    np.random.permutation(california_housing_dataframe.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTB73MNeIYHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note how the code below is slightly different from the previous exercises. Instead of using `median_house_value` as target, we create a new binary target, `median_house_value_is_high`."
      ]
    },
    {
      "metadata": {
        "id": "kPSqspaqIYHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_features(california_housing_dataframe):\n",
        "  \"\"\"Prepares input features from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the features to be used for the model, including\n",
        "    synthetic features.\n",
        "  \"\"\"\n",
        "  selected_features = california_housing_dataframe[\n",
        "    [\"latitude\",\n",
        "     \"longitude\",\n",
        "     \"housing_median_age\",\n",
        "     \"total_rooms\",\n",
        "     \"total_bedrooms\",\n",
        "     \"population\",\n",
        "     \"households\",\n",
        "     \"median_income\"]]\n",
        "  processed_features = selected_features.copy()\n",
        "  # Create a synthetic feature.\n",
        "  processed_features[\"rooms_per_person\"] = (\n",
        "    california_housing_dataframe[\"total_rooms\"] /\n",
        "    california_housing_dataframe[\"population\"])\n",
        "  return processed_features\n",
        "\n",
        "def preprocess_targets(california_housing_dataframe):\n",
        "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the target feature.\n",
        "  \"\"\"\n",
        "  output_targets = pd.DataFrame()\n",
        "  # Create a boolean categorical feature representing whether the\n",
        "  # median_house_value is above a set threshold.\n",
        "  output_targets[\"median_house_value_is_high\"] = (\n",
        "    california_housing_dataframe[\"median_house_value\"] > 265000).astype(float)\n",
        "  return output_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwOYWmXqWA6D",
        "colab_type": "code",
        "outputId": "8ac60b71-8b94-4ecc-fd57-99071f545431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1225
        }
      },
      "cell_type": "code",
      "source": [
        "# Choose the first 12000 (out of 17000) examples for training.\n",
        "training_examples = preprocess_features(california_housing_dataframe.head(12000))\n",
        "training_targets = preprocess_targets(california_housing_dataframe.head(12000))\n",
        "\n",
        "# Choose the last 5000 (out of 17000) examples for validation.\n",
        "validation_examples = preprocess_features(california_housing_dataframe.tail(5000))\n",
        "validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))\n",
        "\n",
        "# Double-check that we've done the right thing.\n",
        "print(\"Training examples summary:\")\n",
        "display.display(training_examples.describe())\n",
        "print(\"Validation examples summary:\")\n",
        "display.display(validation_examples.describe())\n",
        "\n",
        "print(\"Training targets summary:\")\n",
        "display.display(training_targets.describe())\n",
        "print(\"Validation targets summary:\")\n",
        "display.display(validation_targets.describe())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count   12000.0    12000.0             12000.0      12000.0         12000.0   \n",
              "mean       35.6     -119.6                28.5       2657.6           542.0   \n",
              "std         2.1        2.0                12.6       2204.9           419.9   \n",
              "min        32.5     -124.3                 1.0          8.0             1.0   \n",
              "25%        33.9     -121.8                18.0       1469.0           297.0   \n",
              "50%        34.2     -118.5                28.0       2130.0           435.0   \n",
              "75%        37.7     -118.0                37.0       3166.0           654.2   \n",
              "max        41.9     -114.3                52.0      37937.0          5471.0   \n",
              "\n",
              "       population  households  median_income  rooms_per_person  \n",
              "count     12000.0     12000.0        12000.0           12000.0  \n",
              "mean       1432.7       502.9            3.9               2.0  \n",
              "std        1139.5       381.0            1.9               1.2  \n",
              "min           3.0         1.0            0.5               0.0  \n",
              "25%         792.0       282.0            2.6               1.5  \n",
              "50%        1170.0       410.0            3.5               1.9  \n",
              "75%        1728.0       609.0            4.8               2.3  \n",
              "max       35682.0      5189.0           15.0              55.2  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.5</td>\n",
              "      <td>2657.6</td>\n",
              "      <td>542.0</td>\n",
              "      <td>1432.7</td>\n",
              "      <td>502.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2204.9</td>\n",
              "      <td>419.9</td>\n",
              "      <td>1139.5</td>\n",
              "      <td>381.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.5</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1469.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>792.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.2</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>435.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3166.0</td>\n",
              "      <td>654.2</td>\n",
              "      <td>1728.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41.9</td>\n",
              "      <td>-114.3</td>\n",
              "      <td>52.0</td>\n",
              "      <td>37937.0</td>\n",
              "      <td>5471.0</td>\n",
              "      <td>35682.0</td>\n",
              "      <td>5189.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>55.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count    5000.0     5000.0              5000.0       5000.0          5000.0   \n",
              "mean       35.6     -119.6                28.9       2610.1           533.1   \n",
              "std         2.1        2.0                12.4       2118.7           425.3   \n",
              "min        32.6     -124.3                 1.0          2.0             2.0   \n",
              "25%        33.9     -121.8                19.0       1442.0           295.0   \n",
              "50%        34.3     -118.5                29.0       2121.5           430.0   \n",
              "75%        37.7     -118.0                37.0       3118.2           634.2   \n",
              "max        42.0     -114.5                52.0      32627.0          6445.0   \n",
              "\n",
              "       population  households  median_income  rooms_per_person  \n",
              "count      5000.0      5000.0         5000.0            5000.0  \n",
              "mean       1422.1       497.2            3.9               2.0  \n",
              "std        1167.8       392.8            1.9               1.1  \n",
              "min           6.0         2.0            0.5               0.1  \n",
              "25%         782.0       279.0            2.6               1.5  \n",
              "50%        1158.0       407.0            3.5               1.9  \n",
              "75%        1700.2       594.2            4.8               2.3  \n",
              "max       28566.0      6082.0           15.0              34.2  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.9</td>\n",
              "      <td>2610.1</td>\n",
              "      <td>533.1</td>\n",
              "      <td>1422.1</td>\n",
              "      <td>497.2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>2118.7</td>\n",
              "      <td>425.3</td>\n",
              "      <td>1167.8</td>\n",
              "      <td>392.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.6</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1442.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>782.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.3</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2121.5</td>\n",
              "      <td>430.0</td>\n",
              "      <td>1158.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3118.2</td>\n",
              "      <td>634.2</td>\n",
              "      <td>1700.2</td>\n",
              "      <td>594.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>-114.5</td>\n",
              "      <td>52.0</td>\n",
              "      <td>32627.0</td>\n",
              "      <td>6445.0</td>\n",
              "      <td>28566.0</td>\n",
              "      <td>6082.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>34.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       median_house_value_is_high\n",
              "count                     12000.0\n",
              "mean                          0.3\n",
              "std                           0.4\n",
              "min                           0.0\n",
              "25%                           0.0\n",
              "50%                           0.0\n",
              "75%                           1.0\n",
              "max                           1.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value_is_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       median_house_value_is_high\n",
              "count                      5000.0\n",
              "mean                          0.2\n",
              "std                           0.4\n",
              "min                           0.0\n",
              "25%                           0.0\n",
              "50%                           0.0\n",
              "75%                           0.0\n",
              "max                           1.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value_is_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uon1LB3A31VN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How Would Linear Regression Fare?\n",
        "To see why logistic regression is effective, let us first train a naive model that uses linear regression. This model will use labels with values in the set `{0, 1}` and will try to predict a continuous value that is as close as possible to `0` or `1`. Furthermore, we wish to interpret the output as a probability, so it would be ideal if the output will be within the range `(0, 1)`. We would then apply a threshold of `0.5` to determine the label.\n",
        "\n",
        "Run the cells below to train the linear regression model using [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor)."
      ]
    },
    {
      "metadata": {
        "id": "smmUYRDtWOV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns(input_features):\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Args:\n",
        "    input_features: The names of the numerical input features to use.\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\"\n",
        "  return set([tf.feature_column.numeric_column(my_feature)\n",
        "              for my_feature in input_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5OwSrr1yIKD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a linear regression model.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                            \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SE2-hq8PIYHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_regressor_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear regression model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearRegressor` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "\n",
        "  # Create a linear regressor object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_regressor = tf.estimator.LinearRegressor(\n",
        "      feature_columns=construct_feature_columns(training_examples),\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "    \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  training_rmse = []\n",
        "  validation_rmse = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    \n",
        "    # Take a break and compute predictions.\n",
        "    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
        "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
        "    \n",
        "    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "    \n",
        "    # Compute training and validation loss.\n",
        "    training_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(training_predictions, training_targets))\n",
        "    validation_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_rmse.append(training_root_mean_squared_error)\n",
        "    validation_rmse.append(validation_root_mean_squared_error)\n",
        "  print(\"Model training finished.\")\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_rmse, label=\"training\")\n",
        "  plt.plot(validation_rmse, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDBD8xeeIYH2",
        "colab_type": "code",
        "outputId": "dbe6cade-f22c-4c0d-9c31-407dc0dcec6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "cell_type": "code",
      "source": [
        "linear_regressor = train_linear_regressor_model(\n",
        "    learning_rate=0.000001,\n",
        "    steps=200,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 0.45\n",
            "  period 01 : 0.45\n",
            "  period 02 : 0.45\n",
            "  period 03 : 0.44\n",
            "  period 04 : 0.45\n",
            "  period 05 : 0.44\n",
            "  period 06 : 0.44\n",
            "  period 07 : 0.44\n",
            "  period 08 : 0.44\n",
            "  period 09 : 0.44\n",
            "Model training finished.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGACAYAAACgBBhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JjBZ_q7aD9gh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Can We Calculate LogLoss for These Predictions?\n",
        "\n",
        "**Examine the predictions and decide whether or not we can use them to calculate LogLoss.**\n",
        "\n",
        "`LinearRegressor` uses the L2 loss, which doesn't do a great job at penalizing misclassifications when the output is interpreted as a probability.  For example, there should be a huge difference whether a negative example is classified as positive with a probability of 0.9 vs 0.9999, but L2 loss doesn't strongly differentiate these cases.\n",
        "\n",
        "In contrast, `LogLoss` penalizes these \"confidence errors\" much more heavily.  Remember, `LogLoss` is defined as:\n",
        "\n",
        "$$Log Loss = \\sum_{(x,y)\\in D} -y \\cdot log(y_{pred}) - (1 - y) \\cdot log(1 - y_{pred})$$\n",
        "\n",
        "\n",
        "But first, we'll need to obtain the prediction values. We could use `LinearRegressor.predict` to obtain these.\n",
        "\n",
        "Given the predictions and the targets, can we calculate `LogLoss`?"
      ]
    },
    {
      "metadata": {
        "id": "K9gScSoo6iF-",
        "colab_type": "code",
        "outputId": "d4c145c6-bec5-4dde-9cb5-79f455ebfd98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "predict_validation = (lambda: my_input_fn(validation_examples, validation_targets[\"median_house_value_is_high\"], num_epochs=1, shuffle=False))\n",
        "validation_predict = linear_regressor.predict(input_fn=predict_validation)\n",
        "validation_predict = np.array([item['predictions'][0] for item in validation_predict])\n",
        "\n",
        "_ = plt.hist(validation_predict)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQAwGKEGAMBg/x9chCIM18/qPAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dPpJUV862FYI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below to display the solution."
      ]
    },
    {
      "metadata": {
        "id": "kXFQ5uig2RoP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                  validation_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "\n",
        "validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "\n",
        "_ = plt.hist(validation_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYpy336F9wBg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Train a Logistic Regression Model and Calculate LogLoss on the Validation Set\n",
        "\n",
        "To use logistic regression, simply use [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) instead of `LinearRegressor`. Complete the code below.\n",
        "\n",
        "**NOTE**: When running `train()` and `predict()` on a `LinearClassifier` model, you can access the real-valued predicted probabilities via the `\"probabilities\"` key in the returned dict—e.g., `predictions[\"probabilities\"]`. Sklearn's [log_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) function is handy for calculating LogLoss using these probabilities.\n"
      ]
    },
    {
      "metadata": {
        "id": "JElcb--E9wBm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classifier_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearClassifier` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Create a linear classifier object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_classifier = tf.estimator.LinearClassifier(feature_columns=construct_feature_columns(training_examples), optimizer=my_optimizer)\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "  \n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss (on training data):\")\n",
        "  training_log_losses = []\n",
        "  validation_log_losses = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.    \n",
        "    training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
        "    \n",
        "    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
        "    \n",
        "    training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_log_losses.append(training_log_loss)\n",
        "    validation_log_losses.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_log_losses, label=\"training\")\n",
        "  plt.plot(validation_log_losses, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VM0wmnFUIYH9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i2e3TlyL57Qs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below to see the solution.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5YxXd2hn6MuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classifier_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearClassifier` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Create a linear classifier object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)  \n",
        "  linear_classifier = tf.estimator.LinearClassifier(\n",
        "      feature_columns=construct_feature_columns(training_examples),\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "  \n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"LogLoss (on training data):\")\n",
        "  training_log_losses = []\n",
        "  validation_log_losses = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.    \n",
        "    training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
        "    \n",
        "    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
        "    \n",
        "    training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_log_losses.append(training_log_loss)\n",
        "    validation_log_losses.append(validation_log_loss)\n",
        "  print(\"Model training finished.\")\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_log_losses, label=\"training\")\n",
        "  plt.plot(validation_log_losses, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UPM_T1FXsTaL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i-Xo83_aR6s_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Calculate Accuracy and plot a ROC Curve for the Validation Set\n",
        "\n",
        "A few of the metrics useful for classification are the model [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification), the [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and the area under the ROC curve (AUC). We'll examine these metrics.\n",
        "\n",
        "`LinearClassifier.evaluate` calculates useful metrics like accuracy and AUC."
      ]
    },
    {
      "metadata": {
        "id": "DKSQ87VVIYIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\n",
        "print(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47xGS2uNIYIE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You may use class probabilities, such as those calculated by `LinearClassifier.predict`,\n",
        "and Sklearn's [roc_curve](http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics) to\n",
        "obtain the true positive and false positive rates needed to plot a ROC curve."
      ]
    },
    {
      "metadata": {
        "id": "xaU7ttj8IYIF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "# Get just the probabilities for the positive class.\n",
        "validation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
        "    validation_targets, validation_probabilities)\n",
        "plt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\n",
        "plt.plot([0, 1], [0, 1], label=\"random classifier\")\n",
        "_ = plt.legend(loc=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PIdhwfgzIYII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**See if you can tune the learning settings of the model trained at Task 2 to improve AUC.**\n",
        "\n",
        "Often times, certain metrics improve at the detriment of others, and you'll need to find the settings that achieve a good compromise.\n",
        "\n",
        "**Verify if all metrics improve at the same time.**"
      ]
    },
    {
      "metadata": {
        "id": "XKIqjsqcCaxO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TUNE THE SETTINGS BELOW TO IMPROVE AUC\n",
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000002,\n",
        "    steps=500,\n",
        "    batch_size=32,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)\n",
        "\n",
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\n",
        "print(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCugvl0JdWYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for a possible solution."
      ]
    },
    {
      "metadata": {
        "id": "VHosS1g2aetf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "One possible solution that works is to just train for longer, as long as we don't overfit. \n",
        "\n",
        "We can do this by increasing the number the steps, the batch size, or both.\n",
        "\n",
        "All metrics improve at the same time, so our loss metric is a good proxy\n",
        "for both AUC and accuracy.\n",
        "\n",
        "Notice how it takes many, many more iterations just to squeeze a few more \n",
        "units of AUC. This commonly happens. But often even this small gain is worth \n",
        "the costs."
      ]
    },
    {
      "metadata": {
        "id": "dWgTEYMddaA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000003,\n",
        "    steps=20000,\n",
        "    batch_size=500,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)\n",
        "\n",
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\n",
        "print(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}